# 基于深度学习的时序异常检测模型对比实验研究

## Scientific Analysis Report: Deep Learning-based Time Series Anomaly Detection Model Comparison

---

**实验编号**: PSM_comparison_20260125_013217
**分析时间**: 2026年1月25日
**数据集**: PSM (Pooled Server Metrics)
**研究目标**: 评估多种深度学习模型在时序异常检测任务中的性能表现

---

## 摘要

本研究在PSM数据集上系统性地评估了8种深度学习模型在时序异常检测任务中的性能表现。实验采用基于重构误差的异常检测方法，通过准确率、精确率、召回率和F1分数四个核心指标对模型进行综合评估。实验结果表明，TimesNet模型在F1分数上取得了最优性能（0.9735），其通过FFT周期发现和2D卷积建模的创新机制能够有效捕捉时序数据中的复杂周期模式。本研究为农村低压配电网电压异常检测的模型选择提供了重要的实验依据。

---

## 1 引言

### 1.1 研究背景

时序异常检测是工业物联网、智能电网和网络安全等领域的关键技术。随着深度学习技术的快速发展，基于神经网络的时序异常检测方法在近年来取得了显著进展。然而，不同模型架构在面对复杂时序模式时表现出显著差异，因此系统性地评估和比较这些模型的性能具有重要的理论和实践意义。

### 1.2 研究目的

本实验旨在通过标准化的实验设置，在PSM公开数据集上对8种主流深度学习模型进行对比分析，以期为时序异常检测任务中的模型选择提供科学依据。研究重点关注以下问题：

1. 不同模型架构对异常检测性能的影响
2. 精确率与召回率之间的权衡关系
3. 基于周期建模的TimesNet系列模型是否具有优势

---

## 2 实验方法

### 2.1 数据集描述

本实验采用PSM（Pooled Server Metrics）数据集，该数据集来源于eBay服务器监控系统，包含25个特征维度的多变量时序数据。数据集的详细统计信息如表2.1所示。

**表2.1 PSM数据集统计信息**

| 属性 | 数值 |
|:-----|:----:|
| 特征维度 | 25 |
| 训练集样本数 | 132,481 |
| 测试集样本数 | 87,841 |
| 预期异常比例 | 1.0% |

### 2.2 实验模型

本实验评估了8种深度学习模型，涵盖了Transformer架构、线性模型以及基于周期建模的TimesNet系列模型，具体包括：

**基线模型：**
- **Transformer**: 标准Transformer编码器架构，采用自注意力机制建模时序依赖
- **Autoformer**: 引入自相关机制的Transformer变体，专注于序列分解
- **iTransformer**: 倒置Transformer架构，对变量维度进行注意力计算
- **DLinear**: 轻量级线性模型，通过序列分解提取趋势和季节性成分

**TimesNet系列模型：**
- **TimesNet**: 核心创新模型，通过FFT发现周期并利用2D卷积建模周期模式
- **VoltageTimesNet**: 针对电压数据优化的TimesNet变体，融合预设电网周期
- **TPATimesNet**: 三相注意力增强的TimesNet，专门用于三相电力系统
- **MTSTimesNet**: 多尺度时序TimesNet，支持多粒度周期建模

### 2.3 实验设置

所有模型采用统一的超参数配置，以确保公平比较。关键参数设置如表2.2所示。

**表2.2 实验超参数配置**

| 参数 | 设定值 | 说明 |
|:-----|:------:|:-----|
| 序列长度 (seq_len) | 100 | 输入时序窗口长度 |
| 批次大小 (batch_size) | 128 | 训练批次样本数 |
| 训练轮数 (epochs) | 10 | 最大训练迭代轮数 |
| 学习率 (learning_rate) | 0.0001 | 初始学习率 |
| 模型维度 (d_model) | 64 | 隐藏层特征维度 |
| 编码器层数 (e_layers) | 2 | Transformer编码器层数 |
| 注意力头数 (n_heads) | 8 | 多头注意力数量 |
| 早停耐心 (patience) | 3 | 验证损失不下降的容忍轮数 |
| 学习率调整策略 (lradj) | type1 | 指数衰减学习率调度 |

### 2.4 异常检测方法

本实验采用基于重构误差的无监督异常检测方法。模型在正常数据上学习时序模式，通过计算测试样本的重构误差来判定异常。具体流程如下：

1. **模型训练**: 在训练集上学习正常时序模式的重构能力
2. **阈值确定**: 在训练集和测试集的联合重构误差分布上，取第99百分位数作为异常阈值
3. **异常判定**: 重构误差超过阈值的样本被标记为异常

数学表达式如下：

$$\text{threshold} = \text{percentile}(E_{train} \cup E_{test}, 100 - \alpha)$$

$$\hat{y}_i = \mathbb{1}[e_i > \text{threshold}]$$

其中，$E$为重构误差集合，$\alpha$为预期异常比例，$e_i$为第$i$个样本的重构误差。

### 2.5 评估指标

本实验采用以下四个评估指标：

- **准确率 (Accuracy)**: 正确预测的样本比例
- **精确率 (Precision)**: 预测为异常中实际为异常的比例，反映模型的异常检测准确性
- **召回率 (Recall)**: 实际异常中被正确检测的比例，反映模型的异常覆盖能力
- **F1分数 (F1-score)**: 精确率和召回率的调和平均值，综合评估模型性能

此外，实验采用**点调整 (Point Adjustment)** 策略进行评估：若异常段内的任意一点被正确检测，则该异常段内的所有点均被视为正确检测。

---

## 3 实验结果

### 3.1 性能指标汇总

表3.1展示了所有模型在PSM数据集上的异常检测性能。模型按F1分数降序排列。

**表3.1 模型性能对比结果**

| 排名 | 模型 | 准确率 | 精确率 | 召回率 | F1分数 |
|:----:|:-----|:------:|:------:|:------:|:------:|
| 1 | TimesNet | 0.9855 | 0.9848 | 0.9625 | **0.9735** |
| 2 | VoltageTimesNet | 0.9853 | 0.9840 | 0.9625 | 0.9731 |
| 3 | TPATimesNet | 0.9850 | 0.9844 | 0.9612 | 0.9727 |
| 4 | DLinear | 0.9816 | 0.9864 | 0.9466 | 0.9661 |
| 5 | MTSTimesNet | 0.9797 | 0.9756 | 0.9506 | 0.9629 |
| 6 | iTransformer | 0.9722 | 0.9798 | 0.9185 | 0.9482 |
| 7 | Transformer | 0.9524 | 0.9938 | 0.8335 | 0.9066 |
| 8 | Autoformer | 0.9417 | 0.9999 | 0.7899 | 0.8826 |

### 3.2 训练过程分析

图3.1展示了各模型的训练损失收敛曲线。从训练动态来看，可以观察到以下特点：

**TimesNet训练特征:**
- 初始损失: 0.0854 (Epoch 1, iter 100)
- 最终训练损失: 0.0071 (Epoch 10)
- 最终验证损失: 0.0042
- 训练过程平稳，验证损失持续下降，10轮训练全部有效

**Autoformer训练特征:**
- 初始损失: 1.0532 (Epoch 1, iter 100)
- 最终训练损失: 0.9672 (Epoch 8)
- 最终验证损失: 1.6268
- 在第6轮后触发早停机制，表明模型容量可能不足以充分学习数据模式

从损失数量级可以看出，TimesNet的重构能力显著优于Autoformer，最终验证损失相差约390倍（0.0042 vs 1.6268）。

### 3.3 模型性能分析

#### 3.3.1 TimesNet系列模型分析

TimesNet系列的四个模型均取得了优异的性能，F1分数范围为0.9629-0.9735。其中：

- **TimesNet** 以F1=0.9735位居榜首，证明了其FFT周期发现机制的有效性
- **VoltageTimesNet** (F1=0.9731) 与原始TimesNet性能接近，说明预设电网周期与FFT动态发现具有较好的兼容性
- **TPATimesNet** (F1=0.9727) 的三相注意力机制在通用数据集上提升有限
- **MTSTimesNet** (F1=0.9629) 相对较低，可能是多尺度建模在当前数据集上未能充分发挥优势

#### 3.3.2 基线模型分析

- **DLinear** (F1=0.9661) 作为轻量级线性模型，展现出令人瞩目的性能，验证了简单模型在特定场景下的有效性
- **iTransformer** (F1=0.9482) 的倒置注意力机制在变量维度建模上具有一定优势
- **Transformer** (F1=0.9066) 和 **Autoformer** (F1=0.8826) 表现相对较弱

#### 3.3.3 精确率-召回率权衡分析

一个值得注意的发现是精确率与召回率之间的权衡关系：

- **Autoformer** 精确率最高（0.9999），但召回率最低（0.7899）
- **Transformer** 精确率次高（0.9938），召回率同样较低（0.8335）
- **TimesNet** 在精确率（0.9848）和召回率（0.9625）之间取得了最佳平衡

这一现象表明，Autoformer和Transformer倾向于保守预测，仅在高置信度时判定为异常，从而获得极高的精确率但牺牲了大量真实异常的检测。相比之下，TimesNet能够在保持高精确率的同时实现更好的异常覆盖。

---

## 4 讨论

### 4.1 TimesNet优势的理论分析

TimesNet在本实验中取得最优性能，其核心创新在于将一维时序转换为二维张量进行建模。具体而言：

1. **FFT周期发现**: 通过快速傅里叶变换自动识别时序中的主要周期成分，选取top-k个最显著的周期
2. **1D→2D重塑**: 将时序按照发现的周期长度重塑为二维张量，行表示周期内变化，列表示周期间变化
3. **Inception 2D卷积**: 利用多尺度2D卷积核同时捕获周期内和周期间的复杂模式
4. **自适应聚合**: 对多个周期的建模结果进行加权融合

这种设计使TimesNet能够有效捕捉PSM数据中的周期性运行模式，如服务器负载的日周期、周周期等。

### 4.2 Autoformer与Transformer的局限性

Autoformer和Transformer在本实验中表现较弱，可能原因包括：

1. **全局注意力机制的局限**: 标准自注意力机制对所有位置赋予相等的关注机会，可能淹没关键的局部异常模式
2. **序列分解假设**: Autoformer的自相关序列分解机制可能不适用于多变量服务器指标数据的复杂模式
3. **过拟合倾向**: 两个模型的极高精确率和低召回率表明可能存在阈值设置过高的问题，导致保守预测

### 4.3 DLinear的启示

DLinear作为简单的线性模型取得了第4名的成绩（F1=0.9661），这一结果具有重要启示：

1. 复杂模型不一定总是最优选择
2. 序列分解（趋势+季节性）是一种有效的时序建模范式
3. 在计算资源受限的场景下，DLinear可作为高性价比的备选方案

### 4.4 研究局限性

本研究存在以下局限性：

1. **单一数据集**: 仅在PSM数据集上进行评估，结论的泛化性有待在更多数据集上验证
2. **固定超参数**: 所有模型采用相同的超参数配置，未针对各模型进行专门调优
3. **单次实验**: 未进行多次重复实验以评估结果的统计显著性
4. **阈值策略**: 采用固定百分位数阈值，未探索自适应阈值方法

---

## 5 结论

### 5.1 主要发现

本研究在PSM数据集上对8种深度学习模型进行了系统性的时序异常检测性能评估，得出以下主要结论：

1. **TimesNet模型表现最优**，F1分数达到0.9735，其FFT周期发现和2D卷积建模机制能够有效捕捉时序数据中的周期模式
2. **TimesNet系列模型整体表现优异**，四个变体的F1分数均超过0.96，证明了基于周期建模的方法在时序异常检测中的有效性
3. **精确率与召回率存在权衡**，部分模型（如Autoformer）倾向于保守预测，在实际应用中需根据业务需求进行权衡
4. **轻量级DLinear模型具有竞争力**，在特定场景下可作为计算高效的替代方案

### 5.2 实践建议

基于本研究结果，针对农村低压配电网电压异常检测应用，提出以下建议：

1. **模型选择**: 推荐采用TimesNet或VoltageTimesNet作为主要检测模型
2. **阈值调优**: 根据实际应用对误报和漏报的容忍度，适当调整异常检测阈值
3. **模型融合**: 可考虑集成多个模型的预测结果，以进一步提升检测稳定性
4. **数据增强**: 增加更多异常类型的训练数据，以提升模型对复杂异常的识别能力

### 5.3 未来工作

后续研究将从以下方向展开：

1. 在农村电压数据集（RuralVoltage）上进行模型验证
2. 探索模型超参数的自动调优方法
3. 研究异常类型细分检测方法
4. 开发在线增量学习异常检测系统

---

## 参考文献

[1] Wu, H., Xu, J., Wang, J., & Long, M. (2022). TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis. In *International Conference on Learning Representations (ICLR)*.

[2] Wu, H., Xu, J., Wang, J., & Long, M. (2021). Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting. In *Advances in Neural Information Processing Systems (NeurIPS)*.

[3] Zeng, A., Chen, M., Zhang, L., & Xu, Q. (2023). Are Transformers Effective for Time Series Forecasting? In *AAAI Conference on Artificial Intelligence*.

[4] Abdulaal, A., Liu, Z., & Lancewicki, T. (2021). Practical Approach to Asynchronous Multivariate Time Series Anomaly Detection and Localization. In *ACM SIGKDD Conference on Knowledge Discovery and Data Mining*.

---

## 附录

### 附录A 可视化图表索引

本分析报告配套生成了以下可视化图表：

| 图表编号 | 文件名 | 说明 |
|:--------:|:-------|:-----|
| 图A.1 | 训练曲线对比.png | 各模型训练/验证损失变化曲线 |
| 图A.2 | 性能指标对比.png | 四项指标分组柱状图 |
| 图A.3 | 雷达图对比.png | 多维性能雷达图 |
| 图A.4 | 性能热力图.png | 模型×指标热力图 |
| 图A.5 | F1分数对比.png | F1分数排名柱状图 |
| 图A.6 | ROC曲线.png | 多模型ROC曲线对比 |
| 图A.7 | PR曲线.png | 多模型PR曲线对比 |
| 图A.8 | 混淆矩阵_TimesNet.png | 最佳模型混淆矩阵 |

### 附录B 模型训练详细日志

详细训练日志保存于实验目录的各模型日志文件中（*.log）。

---

*本报告由农村低压配电网电压异常检测研究项目自动生成*
*生成时间: 2026-01-25*
*分析工具: Rural Voltage Detection Analysis System v2.0*
