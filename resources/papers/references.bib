@inproceedings{timesnet2023,
  title={TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis},
  author={Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2023},
  pdf={https://ise.thss.tsinghua.edu.cn/~mlong/doc/TimesNet-iclr23.pdf},
  arxiv={2210.02186}
}

@article{dlinear2022,
  title={Are Transformers Effective for Time Series Forecasting?},
  author={Zeng, Mingze and Sheng, Tuo and Yang, Kexin and Chen, Weijun and Jin, Ming and Zhai, Jiaqi},
  journal={arXiv},
  year={2022},
  pdf={https://arxiv.org/pdf/2012.07436v2.pdf},
  arxiv={2012.07436}
}

@inproceedings{patchtst2023,
  title={A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  author={Nie, Yuqi and Nguyen, Nam H. and Sinthong, Phanwadee and Kalagnanam, Jayant},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2023},
  pdf={https://arxiv.org/pdf/2211.14730.pdf},
  arxiv={2211.14730}
}

@inproceedings{itransformer2024,
  title={iTransformer: Inverted Transformers Are Effective for Time Series Forecasting},
  author={Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2024},
  pdf={https://proceedings.iclr.cc/paper_files/paper/2024/file/2ea18fdc667e0ef2ad82b2b4d65147ad-Paper-Conference.pdf},
  arxiv={2310.06625}
}

@inproceedings{autoformer2021,
  title={Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting},
  author={Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021},
  pdf={https://ise.thss.tsinghua.edu.cn/~mlong/doc/Autoformer-nips21.pdf},
  arxiv={2106.13008}
}

@inproceedings{informer2021,
  title={Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021},
  pdf={https://cdn.aaai.org/ojs/17325/17325-13-20819-1-2-20210518.pdf},
  arxiv={2012.07436}
}

@inproceedings{reformer2020,
  title={Reformer: The Efficient Transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2020},
  pdf={https://arxiv.org/pdf/2001.04451.pdf},
  arxiv={2001.04451}
}

@inproceedings{fedformer2022,
  title={FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2022},
  pdf={https://proceedings.mlr.press/v162/zhou22g/zhou22g.pdf},
  arxiv={2201.12740}
}

@inproceedings{lightgts2025,
  title={LightGTS: A Lightweight General Time Series Forecasting Model},
  author={Wang, Yihang and Qiu, Yuying and Chen, Peng and Shu, Yang and Rao, Zhongwen and Pan, Lujia and Yang, Bin and Guo, Chenjuan},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2025},
  pdf={https://openreview.net/attachment?id=Z5FJsp1U3Z&name=pdf},
  arxiv={2506.06005}
}
